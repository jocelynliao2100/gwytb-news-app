import streamlit as st
import pandas as pd
import jieba
import jieba.analyse
from docx import Document
from bs4 import BeautifulSoup
import re
from datetime import datetime
from collections import Counter

# è‡ªè¨‚é—œéµå­—ç¾¤çµ„ï¼ˆç¾åœ‹èˆ‡ç¾æ–¹è¦–ç‚ºåŒç¾©ï¼Œçµ±ä¸€çµ±è¨ˆï¼‰
KEYWORD_CATEGORIES = {
    "å°ç¨ç›¸é—œ": ["å°ç¨", "æ°‘é€²é»¨", "è³´æ¸…å¾·", "è”¡è‹±æ–‡"],
    "åœ‹æ°‘é»¨ç›¸é—œ": ["åœ‹æ°‘é»¨", "é¦¬è‹±ä¹"],
    "ç¾åœ‹ç›¸é—œ": ["ç¾åœ‹"],  # çµ±ä¸€ç‚ºã€Œç¾åœ‹ã€
    "ç¶“æ¿Ÿç™¼å±•èˆ‡äº¤æµç›¸é—œ": ["ç™¼å±•", "å°å•†", "é’å¹´"],
    "å…¶ä»–": ["ä¹äºŒå…±è­˜", "å…©åœ‹è«–", "2758"]
}

# æ‰€æœ‰é—œéµå­—æ˜ å°„ï¼ˆçµ±ä¸€åŒç¾©è©ï¼‰
KEYWORD_ALIAS = {
    "ç¾åœ‹": ["ç¾åœ‹", "ç¾æ–¹"]
}

ALL_KEYWORDS = set()
for v in KEYWORD_CATEGORIES.values():
    ALL_KEYWORDS.update(v)
for v in KEYWORD_ALIAS.values():
    ALL_KEYWORDS.update(v)


def render_keywords_analysis():
    st.title("ğŸ” åœ‹å°è¾¦æ–°èå…§å®¹é—œéµå­—åˆ†æï¼ˆHTML Word æª”ï¼‰")

    uploaded_files = st.file_uploader(
        "ğŸ“‚ è«‹ä¸Šå‚³å¤šå€‹ HTML åŸå§‹ç¢¼æ ¼å¼çš„ Word æª”ï¼ˆ.docxï¼‰",
        type="docx",
        accept_multiple_files=True
    )

    if uploaded_files:
        records = []

        for file in uploaded_files:
            doc = Document(file)
            html = "\n".join(p.text for p in doc.paragraphs)
            soup = BeautifulSoup(html, "html.parser")

            for li in soup.find_all("li"):
                date_tag = li.find("span")
                link_tag = li.find("a")
                if date_tag and link_tag:
                    date = date_tag.text.strip("[] ")
                    content = link_tag.get("title", "").strip()
                    if re.match(r"\d{4}-\d{2}-\d{2}", date) and content:
                        records.append({"æ—¥æœŸ": date, "å…§å®¹": content})

        df = pd.DataFrame(records)
        df["æ—¥æœŸ"] = pd.to_datetime(df["æ—¥æœŸ"], errors="coerce")
        df = df.dropna(subset=["æ—¥æœŸ"])
        df["æœˆä»½"] = df["æ—¥æœŸ"].dt.to_period("M").dt.to_timestamp()

        st.success(f"âœ… æˆåŠŸè¼‰å…¥ {len(df)} å‰‡æ–°èå…§å®¹")
        st.dataframe(df)

        # å…¨æ–‡é—œéµå­—çµ±è¨ˆ
        st.markdown("### ğŸ”  æ‰€æœ‰æ–°èå…§å®¹é—œéµå­—ï¼ˆTop 20ï¼‰")
        full_text = " ".join(df["å…§å®¹"].tolist())
        top_keywords = jieba.analyse.extract_tags(full_text, topK=20, withWeight=True)
        keyword_df = pd.DataFrame(top_keywords, columns=["é—œéµå­—", "æ¬Šé‡"])
        st.bar_chart(keyword_df.set_index("é—œéµå­—"))

        # é—œéµå­—ç¾¤çµ„åˆ†æï¼ˆåŒç¾©è©çµ±ä¸€ï¼‰
        st.markdown("### ğŸ“Š æŒ‡å®šé—œéµå­—ç¾¤çµ„å‡ºç¾è¶¨å‹¢åˆ†æ")
        keyword_monthly = []
        for month, group in df.groupby("æœˆä»½"):
            contents = " ".join(group["å…§å®¹"].tolist())
            for label, words in KEYWORD_CATEGORIES.items():
                for word in words:
                    alias_list = KEYWORD_ALIAS.get(word, [word])
                    count = sum(contents.count(alias) for alias in alias_list)
                    keyword_monthly.append({"æœˆä»½": month, "é—œéµå­—": word, "å‡ºç¾æ¬¡æ•¸": count})

        km_df = pd.DataFrame(keyword_monthly)

        for group_name, keywords in KEYWORD_CATEGORIES.items():
            st.subheader(f"ğŸ“Œ {group_name}")
            filtered = km_df[km_df["é—œéµå­—"].isin(keywords)]
            pivot = filtered.pivot(index="æœˆä»½", columns="é—œéµå­—", values="å‡ºç¾æ¬¡æ•¸").fillna(0)
            st.line_chart(pivot)

            for keyword in keywords:
                subset = km_df[km_df["é—œéµå­—"] == keyword]
                top_months = subset.sort_values("å‡ºç¾æ¬¡æ•¸", ascending=False).head(5)
                st.markdown(f"**ğŸ” {keyword}ï¼šå‡ºç¾æ¬¡æ•¸æœ€å¤šçš„å‰äº”å€‹æœˆä»½ï¼š**")
                st.table(top_months[["æœˆä»½", "å‡ºç¾æ¬¡æ•¸"]])

                for _, row in top_months.iterrows():
                    m = row["æœˆä»½"]
                    m_df = df[df["æœˆä»½"] == m]
                    matched_contents = [t for t in m_df["å…§å®¹"] if any(alias in t for alias in KEYWORD_ALIAS.get(keyword, [keyword]))]
                    with st.expander(f"ğŸ“° {m.strftime('%Y-%m')} å‡ºç¾ {keyword} çš„æ–°èå…§å®¹ï¼ˆå…± {len(matched_contents)} ç­†ï¼‰"):
                        for t in matched_contents:
                            st.markdown(f"- {t}")
    else:
        st.info("è«‹ä¸Šå‚³è‡³å°‘ä¸€å€‹ Word æª”æ¡ˆä»¥é€²è¡Œåˆ†æã€‚")
