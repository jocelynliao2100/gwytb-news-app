import streamlit as st
from docx import Document
from bs4 import BeautifulSoup
import pandas as pd
import re

def render_five_column_analysis():
    st.subheader("ğŸ“‚ äº”å¤§æ¬„ç›®åŸºæœ¬è³‡è¨Šï¼ˆå¤šæª”åˆ†æï¼‰")

    uploaded_files = st.file_uploader(
        "è«‹ä¸Šå‚³å¤šå€‹åœ‹å°è¾¦ Word æª”æ¡ˆï¼ˆHTML åŸå§‹ç¢¼å½¢å¼ï¼‰",
        type="docx",
        accept_multiple_files=True
    )

    def extract_news_from_docx(file):
        doc = Document(file)
        html = "\n".join(p.text for p in doc.paragraphs)
        soup = BeautifulSoup(html, "html.parser")

        column_meta = soup.find("meta", attrs={"name": "ColumnName"})
        column_name = column_meta["content"] if column_meta else "æœªçŸ¥æ¬„ç›®"

        news_items = []
        for li in soup.find_all("li"):
            date_tag = li.find("span")
            link_tag = li.find("a")
            if date_tag and link_tag:
                date = date_tag.text.strip("[] ")
                title = link_tag.get("title", "").strip()
                if re.match(r"\d{4}-\d{2}-\d{2}", date) and title:
                    news_items.append({
                        "æ—¥æœŸ": date,
                        "æ¨™é¡Œ": title,
                        "æ¬„ç›®": column_name
                    })
        return news_items

    if uploaded_files:
        all_data = []
        for f in uploaded_files:
            all_data.extend(extract_news_from_docx(f))

        df = pd.DataFrame(all_data)
        st.success(f"âœ… å…±è§£æå‡º {len(df)} å‰‡æ–°èï¼Œæ¶µè“‹ {df['æ¬„ç›®'].nunique()} å€‹æ¬„ç›®")
        st.dataframe(df)

        st.markdown("### ğŸ§­ å„æ¬„ç›®æ–°èæ•¸é‡")
        st.bar_chart(df["æ¬„ç›®"].value_counts())

        st.markdown("### ğŸ“… å„æ¬„ç›®æŒ‰æ—¥æœŸåˆ†å¸ƒ")
        pivot = df.groupby(["æ¬„ç›®", "æ—¥æœŸ"]).size().reset_index(name="æ•¸é‡")
        pivot_wide = pivot.pivot(index="æ—¥æœŸ", columns="æ¬„ç›®", values="æ•¸é‡").fillna(0)
        st.line_chart(pivot_wide)

    else:
        st.info("è«‹ä¸Šå‚³è‡³å°‘ä¸€å€‹ .docx æª”æ¡ˆä»¥é€²è¡Œåˆ†æ")
